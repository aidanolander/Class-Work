{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "223c1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the outputs in a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ceb1ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf997bdc",
   "metadata": {},
   "source": [
    "Special thanks to [shekhargulati](https://github.com/shekhargulati/sentiment-analysis-python/blob/master/opinion-lexicon-English/negative-words.txt) and [larsyencken](https://gist.github.com/larsyencken/1440509) on Github for the list of negative and stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a9d9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfBadSym(word):\n",
    "    badCheck = 0\n",
    "    for letter in word:\n",
    "        if '@' == letter:\n",
    "            badCheck += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if '\\\\' == letter:\n",
    "            badCheck += 1\n",
    "        else:\n",
    "            pass\n",
    "        if '&' == letter:\n",
    "            badCheck += 1\n",
    "                \n",
    "        else:\n",
    "            pass\n",
    "        if '/' == letter:\n",
    "            badCheck += 1\n",
    "         \n",
    "    if badCheck == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37329a",
   "metadata": {},
   "source": [
    "This is the first function I define, which when called is passed a word and checks whether it includes any of the \"bad\" symbols that we don't want in our data. \n",
    "We will pass this each word in the list of our words from the tweet.txt file below. \n",
    "This could probably be more efficient and only include one if statement, but I had some problems checking lists against lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a20a7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_words = []\n",
    "f = open('Trump_Raw_Tweets_Fall22.txt', 'r')\n",
    "fread = f.read()\n",
    "lower_tweets = fread.lower()\n",
    "bad_symbols = ['!', '?', ',', '.', '\\'', '\\\\', '@', ':', '%', '#', '$', '&', '*']\n",
    "lower_tweets = fread.lower().rstrip('!?:,. @/').lstrip('!?,.: @/').replace(',','').replace('!',\"\").split()\n",
    "clean_tweets = []\n",
    "for word in lower_tweets:\n",
    "    if checkIfBadSym(word):\n",
    "        clean_tweets.append(word)\n",
    "    else:\n",
    "        pass\n",
    "join_tweets = \" \".join(clean_tweets)\n",
    "for sym in bad_symbols:\n",
    "    join_tweets = join_tweets.replace(sym,'')\n",
    "fclean_tweets = join_tweets.split()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefce0b",
   "metadata": {},
   "source": [
    "In this cell, we access the scraped tweets file, read it, and create a list by splitting it, lowering it, and rstripping some of the bad symbols. \n",
    "Unfortunately it still leaves some bad symbols and bits of text we don't want, so that's what the function we defined aboved is for. Afer running it through that, we give it one last rinse and it looks pretty good. Not the cleanest, but it works.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "266f96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"positive.txt\") as p:\n",
    "    pos_words = p.read().splitlines() \n",
    "\n",
    "\n",
    "with open(\"negative.txt\") as n:\n",
    "    neg_words = n.read().splitlines() \n",
    "\n",
    "\n",
    "with open(\"stopwords.txt\") as s:\n",
    "    stop_words = s.read().splitlines() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff52bf",
   "metadata": {},
   "source": [
    "In this cell, we create lists for all the words we'll be checking against. One list for positive words, one for negative, and one for the stop words. \n",
    "By opening it using with, we don't have to worry about closing our files. Also by opening it with read and splitlines, we avoid having a list that includes '\\n' values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f7a15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_counter = 0\n",
    "neg_counter = 0\n",
    "stop_counter = 0\n",
    "total_words = 0\n",
    "other_words = 0\n",
    "for word in fclean_tweets:\n",
    "    total_words += 1\n",
    "    if word in pos_words:\n",
    "        pos_counter += 1\n",
    "    elif word in neg_words:\n",
    "        neg_counter += 1\n",
    "    elif word in stop_words:\n",
    "        stop_counter += 1\n",
    "    else:\n",
    "        other_words += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d946ab8f",
   "metadata": {},
   "source": [
    "Last bit of real work, we actually check the data! \n",
    "We iterate through each word in the final clean tweets clean (fclean_tweets), see if they are positive, negative, or stop words and add to the counter accordingly. If it doesn't fit into any of those lists, we add a value for other words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96928914",
   "metadata": {},
   "source": [
    "# The Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c12efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total positive words counter: 2796\n",
      "total negative words counter: 2105\n",
      "total stop words counter: 22792\n",
      "total other words: 17894\n",
      "positive words make up 6% of the total words\n",
      "negative words make up 5% of the total words\n",
      "stop words make up 50% of the total words\n",
      "other words make up 39% of the total words\n",
      "ratio of positive to negative words is: 1.3282660332541567\n",
      "sum of positive and negative: 691\n",
      "sum of positive, negative, stop, and other: 45587\n",
      "which should equal 45587\n"
     ]
    }
   ],
   "source": [
    "print(\"total positive words counter: %s\" % pos_counter)\n",
    "print(\"total negative words counter: %s\" % neg_counter)\n",
    "print(\"total stop words counter: %s\" % stop_counter)\n",
    "print('total other words: %s' % other_words)\n",
    "\n",
    "pos_percent = \"{:.0%}\".format(pos_counter/total_words)\n",
    "neg_percent = \"{:.0%}\".format(neg_counter/total_words)\n",
    "stop_percent = \"{:.0%}\".format(stop_counter/total_words)\n",
    "other_percent = \"{:.0%}\".format(other_words/total_words)\n",
    "ratio = pos_counter/neg_counter\n",
    "\n",
    "print('positive words make up %s of the total words' % pos_percent)\n",
    "print('negative words make up %s of the total words' % neg_percent)\n",
    "print('stop words make up %s of the total words' % stop_percent)\n",
    "print('other words make up %s of the total words' % other_percent)\n",
    "\n",
    "print('ratio of positive to negative words is: %s' % ratio)\n",
    "\n",
    "print('sum of positive and negative: ' + str(pos_counter - neg_counter))\n",
    "print('sum of positive, negative, stop, and other: ' + str(pos_counter + neg_counter + stop_counter + other_words))\n",
    "print('which should equal %s' % total_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724eafda",
   "metadata": {},
   "source": [
    "Finally, we use a lot of print statements to display the results. It appears that the positive words have a slight lead over the negative words. However, I also know that the positive words include \"trump\", which was the keyword. That may have skewed the results towards a positive sentiment, when in reality they were just referencing the former host of The Apprentice. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
