{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15890cf",
   "metadata": {},
   "source": [
    "# Big Data Assignment 4: White House DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed3c11",
   "metadata": {},
   "source": [
    "Rules:\n",
    "\n",
    "RULE-1: Header to be used as metadata\n",
    "\n",
    "RULE-2: Convert column names into lowercase\n",
    "\n",
    "RULE-3: If a given record is missing visitor \n",
    "        (just the last name of visitor) or \n",
    "        visitee (just the last name of visitee)\n",
    "        , then that record is dropped from all calculations\n",
    "\n",
    "RULE-4: All input must be converted to lowercase letters\n",
    "\n",
    "RULE-5: Your solution has to be generic and \n",
    "        should be able to handle billions of records\n",
    "\n",
    "RULE-6: You have to pass input as a parameter to your PySpark program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9996c",
   "metadata": {},
   "source": [
    "You may download the input from here: https://obamawhitehouse.archives.gov/sites/default/files/disclosures/whitehouse_waves-2016_12.csv_.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1bfc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8898752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.4.25:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe268d85520>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c3b1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used in terminal but not Jupyter Notebooks\n",
    "# input_path = sys.argv[1]  \n",
    "#    print(\"input_path: {}\".format(input_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c670eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path='whitehouse_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ecfcda",
   "metadata": {},
   "source": [
    "### Create pyspark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c16f65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_start = spark\\\n",
    "          .read\\\n",
    "          .format(\"csv\")\\\n",
    "          .option(\"header\",\"true\")\\\n",
    "          .option(\"inferSchema\", \"true\")\\\n",
    "          .load(input_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93ca22b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NAMELAST: string (nullable = true)\n",
      " |-- NAMEFIRST: string (nullable = true)\n",
      " |-- NAMEMID: string (nullable = true)\n",
      " |-- UIN: string (nullable = true)\n",
      " |-- BDGNBR: integer (nullable = true)\n",
      " |-- ACCESS_TYPE: string (nullable = true)\n",
      " |-- TOA: string (nullable = true)\n",
      " |-- POA: string (nullable = true)\n",
      " |-- TOD: string (nullable = true)\n",
      " |-- POD: string (nullable = true)\n",
      " |-- APPT_MADE_DATE: string (nullable = true)\n",
      " |-- APPT_START_DATE: string (nullable = true)\n",
      " |-- APPT_END_DATE: string (nullable = true)\n",
      " |-- APPT_CANCEL_DATE: string (nullable = true)\n",
      " |-- Total_People: integer (nullable = true)\n",
      " |-- LAST_UPDATEDBY: string (nullable = true)\n",
      " |-- POST: string (nullable = true)\n",
      " |-- LASTENTRYDATE: string (nullable = true)\n",
      " |-- TERMINAL_SUFFIX: string (nullable = true)\n",
      " |-- visitee_namelast: string (nullable = true)\n",
      " |-- visitee_namefirst: string (nullable = true)\n",
      " |-- MEETING_LOC: string (nullable = true)\n",
      " |-- MEETING_ROOM: string (nullable = true)\n",
      " |-- CALLER_NAME_LAST: string (nullable = true)\n",
      " |-- CALLER_NAME_FIRST: string (nullable = true)\n",
      " |-- CALLER_ROOM: string (nullable = true)\n",
      " |-- DESCRIPTION: string (nullable = true)\n",
      " |-- Release_Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_start.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711df096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/25 12:49:58 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df_start.createOrReplaceTempView(\"house_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afff712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select NAMELAST, NAMEFIRST, NAMEMID, visitee_namelast, visitee_namefirst from house_table\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c253a",
   "metadata": {},
   "source": [
    "### Create dataframe with relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a24f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aa67466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.createOrReplaceTempView(\"all_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee545d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_query = \"SELECT NAMELAST, NAMEFIRST, visitee_namelast, \\\n",
    "visitee_namefirst FROM all_table WHERE NAMELAST IS NOT NULL AND visitee_namelast IS NOT NULL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c9fa1",
   "metadata": {},
   "source": [
    "### Create a dataframe with non null values and one with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc6890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_null = spark.sql(not_null_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9524826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null = spark.sql(\"SELECT NAMELAST, NAMEFIRST, visitee_namelast, visitee_namefirst FROM all_table \\\n",
    "WHERE NAMELAST IS NULL OR visitee_namelast IS NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6d61e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970504"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad1a5291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911249"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_null.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8901ce5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59255"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af856783",
   "metadata": {},
   "source": [
    "Make sure nulls + non nulls add to total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "577e13c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970504"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_null.count() + df_null.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c8c0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_null.createOrReplaceTempView(\"pull_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84268c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_col_q = \"SELECT LOWER(NAMELAST) as namelast ,LOWER(NAMEFIRST) as namefirst,\\\n",
    "LOWER(visitee_namelast) as visitee_namelast,LOWER(visitee_namefirst) as visitee_namefirst FROM pull_table\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e92087",
   "metadata": {},
   "source": [
    "### Make all values and columns lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e423ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_df = spark.sql(low_col_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb3a7747",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_df.createOrReplaceTempView(\"low_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97fca35",
   "metadata": {},
   "source": [
    "Create grouped by visitor dataframe to see most common visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2582421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visitor = spark.sql(\"SELECT namelast,namefirst, count(*) AS count \\\n",
    "FROM low_table GROUP BY namelast,namefirst ORDER BY count DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c563926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visitor.createOrReplaceTempView(\"visitor_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a05b8b",
   "metadata": {},
   "source": [
    "Create grouped by visitee dataframe to see most common visitees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e053a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visitee = spark.sql(\"SELECT visitee_namelast,visitee_namefirst, count(*) AS count \\\n",
    "FROM low_table GROUP BY visitee_namelast,visitee_namefirst ORDER BY count DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d53e6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visitee.createOrReplaceTempView(\"visitee_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725daec9",
   "metadata": {},
   "source": [
    "Create grouped by visitor and visitee dataframe to see most common meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42ab55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_vis_df = spark.sql(\"SELECT namelast,namefirst,visitee_namelast,visitee_namefirst, count(*) AS count \\\n",
    "FROM low_table GROUP BY namelast,namefirst,visitee_namelast,visitee_namefirst ORDER BY count DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a3f8a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_vis_df.createOrReplaceTempView(\"meet_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7f410",
   "metadata": {},
   "source": [
    "Take top 10 of both visitors, visitees, and meets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0969001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_visitors_q = \"SELECT * FROM visitor_table LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d2e2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_visitees_q = \"SELECT * FROM visitee_table LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8961e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_meets_q = \"SELECT * FROM meet_table LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb222c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_visitors = spark.sql(final_visitors_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71e6ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_visitees = spark.sql(final_visitees_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1dfb4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_meets = spark.sql(final_meets_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08b081",
   "metadata": {},
   "source": [
    "# Outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50bd6589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:>                                                       (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----+\n",
      "|namelast|namefirst|count|\n",
      "+--------+---------+-----+\n",
      "| kidwell|   lauren|  222|\n",
      "|  thomas| benjamin|  196|\n",
      "|    haro|   steven|  183|\n",
      "|  berner|katherine|  177|\n",
      "|   grant|  patrick|  155|\n",
      "|    haas|   jordan|  152|\n",
      "|   garza|   steven|  127|\n",
      "|   cohen|    mandy|  122|\n",
      "|  martin|  kathryn|  122|\n",
      "|   brown| jennifer|  117|\n",
      "+--------+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_visitors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37f0e506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 21:===>                                                    (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+------+\n",
      "|visitee_namelast|visitee_namefirst| count|\n",
      "+----------------+-----------------+------+\n",
      "|          office|         visitors|430881|\n",
      "|           waves|   visitorsoffice| 44129|\n",
      "|          bryant|             ruth| 13970|\n",
      "|           oneil|           olivia| 13155|\n",
      "|        thompson|            jared| 11618|\n",
      "|               /|            potus| 10900|\n",
      "|          burton|           collin|  9672|\n",
      "|           megan|          matthew|  7944|\n",
      "|        mayerson|            asher|  6886|\n",
      "|      dessources|          kalisha|  5289|\n",
      "+----------------+-----------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 21:============================>                            (8 + 8) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_visitees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7ef6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:===>                                                    (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------------+-----------------+-----+\n",
      "|namelast|namefirst|visitee_namelast|visitee_namefirst|count|\n",
      "+--------+---------+----------------+-----------------+-----+\n",
      "| kidwell|   lauren|        yudelson|             alex|  103|\n",
      "|    haas|   jordan|        yudelson|             alex|   90|\n",
      "|   grant|  patrick|        yudelson|             alex|   89|\n",
      "|  thomas| benjamin|        yudelson|             alex|   89|\n",
      "|   cohen|    mandy|         lambrew|           jeanne|   84|\n",
      "|    haro|   steven|        yudelson|             alex|   84|\n",
      "|  berner|katherine|        yudelson|             alex|   82|\n",
      "|   roche|  shannon|        yudelson|             alex|   70|\n",
      "|  urizar| jennifer|         johnson|            katie|   68|\n",
      "|  martin|  kathryn|         lambrew|           jeanne|   61|\n",
      "+--------+---------+----------------+-----------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_meets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d14bd11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59255"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
